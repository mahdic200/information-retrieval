# E10

## مفهوم Tiered indexes یا کلید های لایه بندی شده

این لایه ها مانند لیست های قهرمان یا high low لیست هستند ، و در این مفهوم ما دیگر لیست هارا به دو بخش تقسیم نمیکنیم بلکه آنهارا به چندین لیست تقسیم میکنیم .
به ترتیب در لایه اول تا آخر سند هایی قرار میگیرند که بالاترین امتیاز رو داشته باشند ، و هرچه لایه پایین تر میاد امتیاز هم پایین تر میاد .

درواقع پستینگ لیست های تایر یک برای اون واژه نامه امتیاز بیشتری دارند . برای نمونه ، واژه ی آتو رو در نظر بگیر . سند هایی که توی پستینگ لیست تایر ۲ هستند هم امتیازشون برای واژه ی آتو کمتره به نسبت سند هایی که در تایر یک هستند . توی تایر ۳ نسبت به تایر ۲ کمتره .
یعنی واژه ی آتو در سند ۱ و سند ۲ اومده ولی ایندکسی که براش ساخته میشه توی تایر ۱ سند ۲ امتیاز بالاتری داره . حالا این امتیاز میتونه چی باشه ؟ میتونه بر اساس g(d) محاسبه شده باشه ، بر اساس اعتبار اون سند باشه ، و براساس wf و وزنی که در نظر میگیریم برای اون واژه توی اون سند . تعداد بیشتری ممکنه تکرار شده باشه وزنش هم ممکنه بالاتر رفته باشه .
و بنابراین ما میایم ایندکس های گوناگونی رو طراحی میکنیم برای تایر های گوناگون .
هنگام بازیابی چه اتفاقی میفته ؟ ما میایم فرض میکنیم که فقط تایر ۱ رو داریم ، بازیابی رو براساس تایر ۱ انجام میدیم . اگر k تا سند بازیابی شد که هیچی ، اما اگر k تا سند نتونستیم بازیابی بکنیم ، دیگر سند ها رو از تایر ۲ بازیابی میکنیم . چون ی آستانه ایی هم قراردادیم ، گفتیم اگر از ی آستانه ایی امتیاز سند ها کمتر هست اصلا بازیابی نشند .
فرضا k رو صد در نظر بگیرید ، ی متنی رو کاربر جست و جو میکنه ، میایم توی سند ۱ ، و ۵۰ تا بیشتر نتونستیم بازیابی بکنیم ، اون ۵۰ تای دیگه رو از تایر ۲ بازیابی میکنیم ، ممکنه ۴۰ تا دوباره بتونیم بازیابی بکنیم ، دیگر سند هارو توی تایر ۳ دنبالشون میگردیم ، به این ترتیب میتونیم سند های معتبر تر و با امتیاز بالا تر رو با سرعت بیشتری پیدا کنیم .

## مورد Query term proximity

ما معمولا به مجاورت واژه ها توجه میکنیم . و برامون مهمه که این واژه هایی که نوشتیم توی اون سند هم نزدیک هم اومده باشند . بنابراین این نزدیکی باید لحاظ بشه .
برای نمونه فرض کنید یک متن گرفتید «strained mercy» کوچک ترین پنجره ایی که میتونید در نظر بگیرید که این متن رو پوشش بده اندازه اش ۲ هست ، اگر ی متنی پیدا کردیم توی سند مانند این «mercy is not strained» اینجا کوچک ترین پنجره ۴ هست . حالا ما میتونیم این اندازه هارو به همدیگه ربط بدیم ، هرچقدر اندازه ایی که من توی سند پیدا میکنم به اندازه ی این پنجره ی توی متن جست و جوی من نزدیک تر باشه ، اونوقت من میتونم بگم این نزدیکی بیشتر رعایت شده ، در غیر این صورت خیلی کمتر میشه .

## مفهوم Query parser

خیلی از مواقع ما ممکنه توی این search bar یک متنی رو وارد بکنیم ، ولی اجزایی وجود دارند توی موتور های جست و جو به نام کوئری پارسر ، که کارشون این هست که کوئری های مختلفی رو براساس چیزی که ما وارد کردیم میتونند تولید بکنند و از موتور جست و جو بخوان که نتایج رو براساس کوئری های تولید شده ی اینها بازیابی بکنند .
برای نمونه ما ممکنه توی سرچ بار یک عبارتی رو وارد بکنیم ، کوئری پارسر مثلا میاد چیکار میکنه ؟ اون چیزی که ما وارد کردیم رو به عنوان phrase query در نظر میگیره . phrase query یعنی چی ؟ یعنی چیزی که جست و جو میکنیم دقیقا باید توی سند باشه ، یعنی سند هایی باید بازیابی بشند که دقیقا شامل این عبارت باشند . انگار که متن رو داخل کوتیشن قرار دادند . یعنی ابتدا کوئری رو به عنوان یک فریز کوئری در نظر میگیره و از موتور های جست و جو میخواد که سند هایی رو بازیابی بکنند که دقیقا شامل این عبارت ها باشه .
حالا ممکنه که اون k تا سند مورد نظر ما بازیابی نشه ، یعنی نتایجی که به ما برمیگردونه کمتر از اون تعدادی باشه که مورد نظر ماست . باید بتونیم تعداد سند های بیشتری رو بازیابی کنیم .
حالا میاد چیکار میکنه ؟ میاد اون phrase query رو میشکونه به چند تا کوئری دیگه . فرض کنید که ما چیزی که وارد کردیم به عنوان کوئری این باشه «raising interest rates» افزایش نرخ بهره .
این میاد phrase query میده و تعداد نتایجی که بازیابی میکنه کمتر از k هست . میاد این رو میشکنه به دو تا کوئری دیگه ، به raising interest و interest rates .
پس یک phrase query طولانی تر رو میشکونه به چند تا phrase query کوتاه تر . و از موتور جست و جو میخواد که حالا سند هایی رو بازیابی بکنه که دارای این phrase query ها باشند .
و بعد میاد سند هایی که بازیابی کرده رو براساس یک شاخصی رتبه بندی میکنه . و بنابراین نتایج رو به صورت رتبه بندی شده نمایش میده .
اگر موفق نشد و نتایجی که میخواست نمایش بده کمتر از k بود میاد جداگانه در نظر بگیره . یعنی متن جست و جوی مارو دیگه نمیشکونه به دو تکه ، واژه به واژه رو در نظر میگیره و از موتور جست و جو درخواست میکنه تا سند هایی رو بازیابی کنه که دارای واژه های متن جست و جو باشند (بدون توجه به ترتیب) . بعد دوباره سند هارو براساس امتیاز رتبه بندی میکنه .

پس یکی از کار هایی که این کوئری پارسر ها انجام میدن اینه که میان متن جست و جوی شمارو دستکاری میکنند تا نیاز اطلاعاتی شمارو بهتر پاسخ بدن .

اکنون اگر ما امتیاز های گوناگونی رو لحاظ کردیم ، مانند شباهت کسینوسی یا g(d) یا proximity score . خب سند های گوناگون امتیاز های گوناگونی بر پایه ی شاخص ها میگیرن . یعنی یک سندی ممکنه proximity بسیار خوبی داشته باشه یا شباهت کسینوسی خیلی خوبی داشته باشه ولی خیلی معتبر نباشه . یا ی سندی اعتبار خیلی زیادی داشته باشه اما شباهت کسینوسی زیادی نداشته باشه . چه ضریبی باید برای اینها در نظر بگیریم ؟

در بعضی از نرم افزار ها ممکنه یک متخصصی بیاد به ما بگه ضرایب رو باید اینجوری در نظر بگیری ، بعضی ها ممکنه بیان بگن ضریب اعتبار خیلی مهم تره .
اما واقعیت اینه که معمولا این ضرایب رو با رویکرد های ماشین لرنینگ تعیین میکنند .

یعنی یک مدلی رو آموزش میدن ، بعد از اون مدل آموزش دیده استفاده میکنند تا بیان این ضرایب رو تعیین بکنند .

(اینجا توی شکل ی سری چیزها توضیح داده شده ، ویدیو رو باید ببینی) .

