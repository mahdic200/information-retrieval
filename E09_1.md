q# E09

## مفهوم Champion list

در جلسه های پیشین در مورد این صحبت کردیم که چجوری میتونیم سرعت موتور های جست و جو رو افزایش بدیم . برای این دو راهکار کلی پیشنهاد کرده بودیم . یدونش اینه که بیایم و تعداد واژه هایی که توی متن جست و جو استفاده شده رو کاهش بدیم . مثلا واژه هایی که idf اونها پایین هست tf-idf کوچکی ایجاد میکنند و باعث میشوند که امتیاز مربوط به ی سند خیلی افزایش پیدا نکنه .
راهکار دوم این بود که ما بیایم posting list هارو کوتاه بکنیم و مثلا doc-id هایی که wf کمی دارند (weight frequency) ، یعنی تعداد تکرار های مربوط به اون واژشون پایین هست رو بیایم حذف کنیم .

- کم کردن واژه های موجود در متن جست و جو
- کوتاه کردن posting list ها

در همین راستا میان و از یک مفهومی استفاده میکنند به نام champion list که هدفشون کوتاه کردن تعداد سند های موجود در posting list واژه ها هست ، نه فقط متن جست و جو ، مربوط به کلیه واژه ها .


فرض میگیرند ما یک واژه نامه داریم که دارای واژه های گوناگونی هست . برای هر واژه ما یک posting list داریم . به جای اینکه بیایم و اون امتیاز هارو روی همه ی posting list محاسبه بکنند ، میان و کل posting list رو در نظر نمیگیرند . r تا سند رو برای این واژه در نظر بگیرید . حالا r چیه ؟ تعداد سند هایی که بیشترین وزن رو دارند . حالا این وزن میتونه بر اساس tf-idf باشه .

حالا موقعی که میخوان جست و جو انجام بدیم ، به جای اینکه روی همه ی posting list اون امتیاز رو حساب کنیم ، میایم روی اون r تا سندی که بیشترین وزن رو داره امتیاز محاسبه میکنیم . یعنی کدوم سند ها در رقابت هستند ؟ اون r تایی که بیشترین امتیاز رو دارند .

این champion list ها موقع جست و جو ساخته نمیشن ، خیلی قبل تر زمان index کردن ساخته میشند .

این r میتونه توسط یک خبره توی اون حوزه تعیین بشه یا میتونه به عنوان یک hyper parameter بهینه بشه .
اما نکته ایی که وجود داره اینه که ما موقع کوئری گرفتن میتونیم مشخص کنیم چند تا نتیجه برای ما بازیابی بشه .

میگفتیم k-top document و بر اساس امتیاز سند بود ، حالا اگر این k رو ما بیشتر از r در نظر بگیریم چه اتفاقی میفته ؟ اون سند هایی که بازیابی میشند که تعدادشون r هست ، از تعداد نتایجی که انتظار داریم k کمتر میشه و این یک نقصه .

#### خلاصه

به ازای هر واژه ما یک فهرستی رو به عنوان champion list در نظر میگیریم که حالا فهرست برتر یا قهرمان هم بهش میگند . و موقع کوئری گرفتن تمرکز میکنیم روی این champion list ها.

رویکردی که ما برای بازیابی سند ها تا اکنون داشتیم شاخص tf-idf بود . اونی که tf-idf بیشتری داشت بازیابی میشد .

اما الان google فقط بر این اساس برای ما سند هارو بازیابی نمیکنه . پارامتر مهم دیگه ایی که در نظر گرفته میشه اعتبار یک سند هست ، صرفا شباهت متن جست و جو با سند مورد نظر تعیین کننده نیست ، بلکه اعتبارش هم مهمه .

یکی از معیار ها برای اعتبار سنجی مقاله ها ارجاع هست . که چقدر ارجاع میشه به اون مقاله . یک سری ها اومدند و این رو اصلاح کردند و گفتند خود ارجاعی رو باید حذف کنید (ی کسی هی مقاله های خودش رو ارجاع بده) چون این مهم نیست .

بعضیام گفتند که دیگران هم به شما ارجاع بدند مهم نیست ، ISI مهمه به شما ارجاع داده باشه یا نه .

#### جمع بندی

یک موتور جست و جو هم باید شباهت رو در نظر بگیره هم اعتبار یک سند رو در نظر بگیره و این دو رو در کنار هم ببینه .

## مفهوم net score

### اعتبار یک سند g(d)

### $$net-score(q,d) = g(d) + cos(q,d)$$

# روش هایی که میتونیم این net-score هارو سریع تر حساب کنیم

## رویکرد top k by net score

تو حالت قبلی ، زمانی که inverted index معمولی داشتیم ، میومدیم posting list های مربوط به هر واژه رو بر اساس doc-id اونها مرتب میکردیم . و بعد میومدیم شبه کد مربوط به شباهت کسینوسی رو اعمال میکردیم .

این دفعه برای اینکه g(d) رو دخالت بدن میان بر اساس g(d) اونها رو مرتب میکنند . چرا ؟ چون g(d) مستقل از متن جست و جو هست و بنابراین شما زمان index time میتونید posting list های مربوط به هر واژه رو بر اساس اعتبارشون مرتب کنیم به صورت نزولی . بیشترین اول و کمترین آخر .

چه فایده ایی داره این کار ؟ نخست اینکه چون ما یک ترتیب و سازمان دهی ایجاد کردیم ، ما میتونیم این الگوریتم شباهت کسینویسی رو میتونیم به صورت همروند برای سند ها حساب کنیم و هیچ خللی هم وارد نمیشه ، در اون شبه کد .

بنابراین هم میتونیم posting intersection رو به صورت همروند انجام بدیم و هم محاسبه ی شباهت کسینویس رو به صورت همروند انجام بدیم .

مثلا فرض کنید که سه تا واژه داریم توی متن جست و جو و واژه ی نخست خودش یک posting list داره که بر اساس g(d) مرتب شده و واژه ی دوم هم همین جور و واژه ی سوم هم همین جور . ما میتونیم به صورت موازی بریم سراغ واژه ی نخست ، یک نخ هم برای واژه های دیگه . آنگاه به صورت همگام ما میتونیم این هارو با هم مقایسه کنیم .

خیلی راحت میتونیم اشتراک بگیریم . اگر هم بخوایم شباهت کسینوسی رو اضافه کنیم میتونی به صورت همروند میتونیم امتیاز مربوط به اون سند ، tf-idf رو اضافه کنیم .

# چرا بر اساس g(d) مرتب میکنیم ؟

خیلی از زمان ها هست که برنامه هایی داریم ، که در اونها زمان اولویت نخست هست ، یعنی چی ؟ یعنی شاید مهم نباشه که همه ی سند هارو برگردونیم ، مهم اینه که سند هارو زودبرگردونیم چون زمان ملاک نخسته و دقت اونقدر مهم نیست .

برای نمونه شاید از ما بخوان توی 50 میلی ثانیه پاسخ بدیم و امکانش خیلی بالاست که توی این 50 میلی ثانیه ما نتونیم محاسبات خودمون رو کامل کنیم . میایم پیش از محاسبات در زمان index time بر اساس g(d) مرتب میکنیم ، و وقتی از ما نتایج رو بخوان سازمان دهی شده همه چیز رو داریم ، و میتونیم پاسخ زودتری بدیم . چطور ؟ میایم محاسبات خودمون رو به سند هایی که g(d) بالاتری دارند اختصاص میدیم و زمان رو برای سند های دیگه هدر نمیدیم .

- نیاز اطلاعاتی کاربرمون رو بهتر پاسخ میدیم
- در سامانه هایی که زمان اولویت نخست اونها هست میتونیم عملکرد بهینه تری داشته باشیم

## مورد champion lists in g(d) ordering

$$g(d) + tf-idf_{td}$$

