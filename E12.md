# E12_1

## مفهوم Variance

وقتی MAP رو برای موتور های جست و جو روی کوئری های گوناگون اندازه گیری میکنی این واریانسش زیاد میشه . این زیاد و کم شدن واریانس به این دلیل نیست که موتور جست و جوی ما موتور خوبی نیست . ممکنه اون پرس و جو پرس و جوی دشواری باشه . یعنی ممکنه موتور جست و جویی که ما طراحی میکنیم ممکنه قابل رقابت با موتور های جست و جوی پیشرفته باشه ، حتی ممکنه موتور های جست و جو پیشرفته هم همینجوری بشن . واریناسشون زیاد باشه .

برای اینکه MAP رو بخوایم اندازه گیری کنیم ، ما دیتاست های تست مختلفی داریم . بهش میگن کورپِس . این کورپس های ما مجموعه هایی هستند از سند های مختلف ، چجوری تبدیل به تست کالشکن میشن ؟ زمانی که ما ی سری کوئری تعریف بکینم ، و مرتبط یا نامرتبط بودن این کوئری هارو مشخص کنیم .

یک سری آدم اونجا نشستن و دارن سند هارو برچسب گذاری میکنن ، براساس کوئری ها . حالا این کوئری ها توسط چه کسانی طراحی میشن ؟ توسط متخصصین اون دامنه .

طراحی کوئری ی طرف قضیه است . برای تگ زدن ها هم همینطوره . ی عامل انسانی میاد اون سند هارو تگ میزنه و بسیار زمان بره . و اصلا یک نفر این کاررو انجام نمیده ، یک تیم این کاررو انجام میده .

## شاخص های داور های انسانی

باید ی مقدار تفاهم بین اینها باشه ، نباید دو نفر بیان که کلا متضاد فکر میکنن . باید باهمدیگه تفاهم داشته باشن . باید تفکراشون به همدیگه بخوره . پس بهتر هست ما بیایم از افرادی استفاده بکنیم که تفاهمشون ضریب خوبی داشته باشه . ما مجبوریم بیایم یک ضریبی رو محاسبه کنیم که نشون دهنده ی تفاهم باشه ، فرض میکنیم دو داور داریم . بعدا تعمیمش میدیم به چندین داور .

چجوری این کاررو میکنیم ؟ میگیم آقای شماره ی یک ، شما بیا نظرت رو در مورد سند ها بده . آقای شماره ی دو ، شمام نظر بده .

## ضریب kappa measure for inter-judge (dis)agreement

دو تا احتمال رو باید بدست بیاریم تا ضریب کاپا بر اسا این دو احتمال محاسبه بشه .
- احتمال P(A) نسبتی که اینها باهم تفاهم داشتن . به صورت نسبی تعداد دفعاتی هست که این داور ها باهم موافق بودند . میشه تعداد سند هایی که باهم موافق بودند تقسیم بر تعداد کل سند ها .
- اما P(E) چقدر از این تفاهم ها شانسی بوده . راه حلی هم که پیشنهاد داده میگه کل نظر های داور های یک و دو رو کنار هم قرار بدیم ، اینجا میشه دو تا ۴۰۰ تا نظر ، از توی اینها به من بگو احتمال مرتبط ها کدومه ، احتمال نامرتبط ها کدومه .

احتمال شانسی گفتن یا P(E) میشه احتمال مرتبط به توان دو بعلاوه احتمال مرتبط به توان دو .

ضریب کاپا :

$$kappa = { {P(A) - P(E)} \over {1 - P(E)} } $$

اگر ضریب کاپا بالای هشتاد درصد بود اونوقت تفاهم خیلی خوبه . ولی اگه بین شصت و هفت صدم و هشت دهم بود اون موقع مناسب هست (هی ، بد نیست) و اگر کمتر از شصت و هفت صدم باشه اونوقت دیگه کار پیچیده میشه .

حالا وقتی که تعداد داور ها از دونفر بیشتر میشه ، ما برای اینکه بررسی بکنیم که آیا ضریب کاپا حالت fair داره ، کاری که باید انجام بدیم اینه که دو به دو ضریب داور هارو در میاریم ، داور اول با دوم ، دوم با سوم ، اول با سوم . اینهارو برمیداریم میانگین میگیریم .

## مفهوم Pulling

مفهوم پولینگ . از اونجایی که پایگاه داده ها اندازشون خیلی زیاده و سند های بسیار زیادی رو دارا هستند ، نمیشه عملا به ازای هر کوئری تمامی سند هارو ما بیایم تگ بزنیم به عنوان مربوط یا نامربوط .

میایم از موتور های جست و جوی دیگر استفاده میکنیم برای اینکه بتونیم راحت تر این کاررو انجام بدیم . ی کوئری میدیم به موتور جست و جو ، و اعمال میکنن روی پایگاه داده ایی که دارند . نتایجی که اون موتور جست و جوی دیگر بازیابی کرده رو بر میدارن تگ مرتبط یا نامرتبط بهش میزنن . درواقع اومدن از یک کمک کننده ایی استفاده کردن .

## اثر inter-judge agreement

اگر افراد دیگری رو بخواید استفاده بکنید و شخص رو عوض بکنید ، این بازدهی که شما اندازه گیری میکنید برای موتور های جست و جو ممکنه متفاوت باشه . ممکنه تگ هایی که نفر قبلی نزده این بزنه .

اما نکته ایی که وجود داره ، همین اشخاص دارن ارزیابی میکنن نتایج یک موتورجست و جوی دیگر رو .

## نقد به pure relevance

یعنی شما به چیز دیگه ایی نگاه نکنید و فقط به مرتبط بودن سند ها نگاه بکنید . اما نکته ایی که وجود داره ، یک موتور جست و جو اگر بخواد بر اساس pure relevance  کار بکنه یک مشکلی داره و اونم مشکل diversity هست . یعنی فرض کنید یک موتور جست و جویی دارید یک کوئری به شما میده ، صفحه اولی که به شما میده همه صفحه ها شبیه همدیگه باشند ، مطالب همدیگه رو کپی کردن .

یعنی ما لینک هارو باز میکنیم میبینیم همه شبیه همدیگه هستند . بنابراین این باعث خوشحالی و رضایت کاربر نمیشه . آخرش ما دنبال این بودیم بتونیم رضایت کاربر رو ایجاد بکنیم . رضایت کاربر با نتایج تکراری ایجاد نمیشه . بنابراین به جای اینکه برم pure relevance رو در نظر بگیرن بهتره بیان marginal relevance رو در نظر بگیرن .

## آیا میتونیم از قضاوت انسانی دوری کنیم ؟

خیر نمیتونیم ، ما قراره رضایت انسان رو برطرف بکنیم ، بنابراین از اونجایی که هدف برآورده کردن رضایت همون آدمه ، بهتره که از همون آدم نظرسنجی کنیم .
هرچند که تهیه ی این benchmark ها بسیار زمان بر و هزینه بر خواهد بود و بخاطر همین هم هست که تیمی کار میکنن و بودجه های بسیار زیادی میگیرن ولی ارزشمنده .

## ارزیابی روی موتور های جست و جوی بزرگ

ریکال رو نمیتونیم خیلی در نظر بگیریم . چون در دنیای واقعی اینکه بخوایم ببینیم درکل چند سند توی کل دنیا وجود داره که بعد بخوایم نسبتش رو اندازه بگیریم تقریبا کار غیر ممکنیه .

یک معیار میتونه کلیک کردن باشه .

## مفهوم A/B testing

فرضا ی موتور جست و جوی بزرگ داریم ، ی فیچری رو میایم اضافه میکنیم ، میخوایم ببینیم این ویرایشی که انجام دادیم آیا باعث بهبود نتایج میشه یا خیر . ی هو نیاید اون نسخه ی جدید رو جایگزین کنید با موتور جست و جوی قبلی . اینجوری نیست که تا ی چیزی جدید ساخته میشه درجا بزاریمش روی سرور . ممکنه باعث بهبود نشه . میان یک درصد از کوئری هایی که سمتشون میاد رو میفرستن رو موتور جست و جوی جدید . درصد کمی رو میفرستن اونور . اگر باعث بهبود نتایج شد و رضایت کاربران بیشتر شد کم کم ترافیک رو میبرم سمت موتور جست و جوی جدید و به این ترتیب میتونم یک روال تدریجی رو انجام بدم برای اینکه کاربرام بتونن مهاجرت کنن روی موتور جست و جوی جدیدم ، کاربرام حس نمیکنن چیزی رو چون این کار تدریجی انجام میشه .

## ارائه ی نتایج

حالا نتایج بازیابی شده ، فرض کنید جست و جو کردید و نتایج اومده ، حال این نتایج رو چجوری برای کاربر فراهم بکنم که منجر به رضایت بیشتر کابر بشه ، کاربر بیشتر از موتور جست و جوی من استفاده بکنه ، وقتش رو کمتر صرف بکنه .

یکی از این کارهایی که انجام میدن و خیلیم مهمه خلاصه سازی نتایجه و ما هم بسیار از این استفاده میکنیم ، فرضا کاربر یک چیزی رو جست و جو میکنه و اون لینکی که بهش نمایش داده میشه اون پایینش یک خلاصه ایی از وب پیج رو به کاربر نمایش میده اینکه کاربر ببینه اون نیاز اطلاعاتیش تا حدودی توی اون خلاصه وجود داره باعث میشه که کلیک کنه روی اون لینک و این خودش نشون دهنده ی اینه که موتور جست و جوی ما خوب هست .

پرسش اینجاست که این خلاصه ها چجوری میتونن ایجاد بشن . خلاصه رو چجوری ما باید ایجاد کنیم ؟ خلاصه به دو شیوه میتونه انجام بشه ، یک رویکرد خلاصه سازی به صورت ایستا هست ، یک رویکرد به صورت پویا هست .

## خلاصه سازی ایستا

توی خلاصه سازی به صورت ایستا ، هر وب پیجی یک خلاصه ایی ازش استخراج میکنن فارغ از متن جست و جو . یعنی برای نمونه ما کوئری شماره ی ۱ رو وارد کردیم و وب پیج x برای ما بازیابی شد همون خلاصه ایی برای ما نمایش داده میشه که کوئری شماره ی ۲ رو وارد بکنیم و پیج x برای ما بازیابی بشه و با تغییر کوئری خلاصه هم تغییری نخواهد کرد .

## خلاصه سازی پویا

اما توی خلاصه سازی پویا دقیقا خلاصه ایی که ایجاد میشه به کوئری ما وابسته است و اگر متن جست و جو رو عوض کنیم اون خلاصه ایی هم که نمایش داده میشه متفاوت خواهد بود .

## چگونگی خلاصه سازی ایستا

ساده ترین رویکردی که استفاده میشد این بود که یک تعداد واژه های اول هر سند رو میومدن نشون میدادن که زمان ایندکس میتونستن این رو ذخیره بکنن . به ازای هر سند یک خلاصه ایی از اون وب پیج رو داشته باشن اما روش ها پیچیده تر شدن و اومدن از NLP استفاده کردن ، از تکنیک های پردازش زبان طبیعی استفاده کردن برای اینکه بتونن از داخل یک متن خلاصه بکشن بیرون .

خلاصه سازی متن یک فیلد بسیار گسترده ایی هست تو دامنه ی متن . مث این میمونه که بگیم توی پردازش تصویر ما یک دامنه ایی داریم به نام حذف نویز .

توی NLP شما یک دامنه ایی دارید به نام خلاصه سازی متن . یک متن بدیم و چجوری روش خلاصه سازی انجام بشه .

## چگونگی خلاصه سازی پویا

توی پویا میان از یک پنجره استفاده میکنن ، باید یک پنجره ایی رو باید دربیاری که توی این پنجره اون واژه های موجود در کوئری وجود داشته باشه ، بعد میان حالا جمله هایی رو از داخل همون پنجره استخراج کنن و اون هارو به کاربر نشون بدن .

### نکته در مورد تکنیک پنجره

اگر از این رویکرد دارید استفاده میکنید باید توجه داشته باشید که شما به ازای هر کوئری شما ، باید بیاید جست و جو بکنید کل اون سند رو تا بتونید اون پنجره هارو پیدا بکنید ، یعنی بسیار زمان بر خواهد شد . بنابراین باید دنبال روش هایی باشید که خیلی سریع این کاررو انجام میدن ولی تو حالت ایستا خوبیش این بود که اصلا همچین کاری انجام نمیدید .

ولی خب الان میدونیم که الان خلاصه هایی که به ما نشون میدن تا چند سال قبل اینجوری نبود . ولی الان میبینیم گوگل چندین ساله که خلاصه هایی که نشون میده همش از نوع پویا هست و اون واژه متن های جست و جوی شما وجود داره توی جملاتی که توی اون خلاصه به ما نشون میده ، حالا ما میتونیم پنجره های گوناگونی رو استخراج بکنیم ، ویژگی هایی رو استخراج بکنیم از اون پنجره ها و ی جوری رتبه بندی بکنیم اون پنجره هارو و پنجره های مناسب رو بر اساس ویژگی هایی بیایم به کاربر نشون بدیم .

موقعیت پنجره ، طول پنجره و از موارد هم بسیار مهمه و میتونن تاثیر بدن این رو و امتیازدهی کنن .

توی نتایجی که موتور جست و جو داره نشون میده ، اگر اون لینک های مهمی که توی اون صفحه وجود داره رو هم بیاد به کاربر نشون بده این میتونه منجر به این بشه که اون کاربر زودتر به اون لینک مورد نظرش دسترسی داشته باشه .
