# E04

## توضیح سریع راجع به hash

در آرایه ها ، هر خانه یک شماره ایی داشت که اگر میخواستیم بررسی کنیم مقدار مورد نظر ما در خانه ایی وجود دارد باید تقریبا تمام آن آرایه را پیمایش و با یک شرط مقدارمان را پیدا میکردیم . اما در ساختمان داده ی hash اینگونه نیست . در ساختمان داده ی hash شما یک کلید را به hash میدهید و هش به شما شماره ی خانه ی مورد نظرتان را میدهد . این توضیح بسیار کوتاه و با هدف یادآوردی درس ساختمان داده است . پیشنهاد میشود یک مرور دوباره از ساختمان داده ی هش داشته باشید .

> [!IMPORTANT] نکته ی منفی
> اگر واژگان شما تغییرات خیلی کمی داشته باشند آن تابع هش به احتمال خیلی زیاد ایندکس متفاوتی رو نخواهد داد .
> وقتی تعداد زیادی از مقادیر قرار باشد که در ساختمان داده ی هش ذخیره شوند و تعداد کم و زیاد شود ، باید دوباره عملیات هش را انجام دهیم ، برای کل داده ها و این یک نکته ی منفی است .


## ساختمان داده ی tree

تمام خوبی درخت جست و جوی دو دویی اینه که مرتب باشه .

میتونیم از این ساختمان داده استفاده کنیم تا vocabulary خودمون رو بسازیم .

درختان دو دویی درسته که جست و جو کردن رو نسبت به هش کندتر انجام میدند . ولی ی سری انعطاف پذیری هایی دارند که هش نداره .

## مورد wildcard queries

برای نمونه شما با هش نمیتونستید ***wildcard queries*** بگیرید . اینها کوئری هایی هستند که شما میتونید از * استفاده بکنید داخلشون برای اینک دنبال کلماتی بگردید که نمیدونید دقیقا بجای * چه چیزی قرار میگیره . مثلا `*mon` . اینها رو چجوری پیدا میکنیم ؟
مثلا در درختمون از کاراکتر m شروع میکنیم . بعد میریم سمت راست ، تا جایی که به کلمه ی mon میرسیم . حالا دیگه خود اون گره و تمامی واژگانی که زیر اون درخت قرار دارند میشن جواب .

حالا فرض کنیم واژه ایی مانند `mon*` رو میخوایم پیدا کنیم . این رو باید با یک ترفندی پیدا کنیم ، باید رشته رو وارون کنیم و بعد شروع کنیم به پیدا کردن چیزی که میخوایم . یعنی ما `*nom` رو باید پیدا کنیم . یعنی یک درخت وارون باید بسازیم .


حالا چجوری `m*nchen` رو پیدا کنیم ؟ این رو باید دو تکه کنیم ، نخست به دنبال `*m` و سپس به دنبال `nchen*` در درخت دو دویی میگردیم و محل برخورد این دو میشه جواب ما ، یعنی جایی که اشتراک اینها در درخت میشه . و نکته اش اینه که باید درخت وارون رو هم باید برای پیدا کردن عبارت دوم داشته باشیم .

## شاخص permuterm-index

ما میتونیم با استفاده از این permuterm-index تعداد مقایسه هامون رو کم بکنیم . اون هم دوباره از درخت دودویی استفاده میکنه ولی دیگه از دوتا درخت استفاده نمیکنه . میاد از یک درخت استفاده میکنه ، یک درخت بزرگتر ، منتها توی اون درخت بزرگتر تعداد مقایسه ها کاهش پیدا میکنه .

#### چجوری ساخته میشه این ؟

هرواژه ایی که توی لغت نامه ما یا vocabulary وجود داره یک `$` رو تهش میزاریم و این علامت دلار رو شیفت میدیم به سمت چپ ، اینجوری :

```
hello$ --> ello$h --> llo$he --> lo$hel --> o$hell --> $hello
```

یعنی به ازای هر واژه چندین واژه ی جدید ایجاد میشه . و مجموعه ی بسیاز بزرگتری خواهید داشت و چندین برابر میشه .
اینکه چند برابر میشه بستگی به این داره که میانگین تعداد کاراکتر های واژه های اون زبان چندتا باشه . مثلا اگر ۸ کاراکتر باشه ۸ برابر میشه .

و حالا دیگه مثلا hello نداریم و چیزهایی که ازش ساختیم رو داریم .

> [!IMPORTANT] مشکلات
> یکی از بزرگترین مشکلات این شاخص حافظه ی زیادیه که نیاز داره تا بتونه پردازشش رو انجام بده .


## چرا بااینکه اندازه ی درخت permuterm بزرگتره اما جست و جو سریع تر انجام میشه ؟

این permuterm سرعت جست و جو رو سریع تر میکنه در مقاسیه با b-tree معمولی . چرا ؟ چون توی جست و جویی که بالاتر بررسی شد ، جست و جوی b-tree شما باید دو تا درخت رو میساختی و بررسی میکردی ، یعنی درجه ی اجراییت دو تا $log(n)$ بود ، اما اینجا مثلا میشه $log(n) + 2$  و این خیلی فرق میکنه اندازه اش .
درسته که درجه اجرایی جفتشون $log(n)$ هست اما ضرایبشون فرق میکنه و ضریب خیلی تاثیرگذاره .

## شاخص k-gram index

این بوجود اومده تا مشکل permuterm-index رو حل کنه . ساده ترین حالت k-gram که این k میتونه اعداد مختلفی باشه مثلا ۲ یا ۳ یا ۴ یا هرچی . که bigram خیلی معروف تره نسبت به بقیه . که میشه ۲ گرم .

یک جلمه در نظر بگیرید ، نمونه : April is the cruelest month we get the bigrams ، اگر بخوایم بایگرم های این رو حساب بکنیم به ترتیب ، ابتدا و انتهای هر واژه ی این جمله رو `$` میزاریم . اونوقت دو تا دوتا کاراکتر هارو جدا و هرکدوم رو به عنوان یک واژه در نظر میگیریم . برای نمونه :

```
April --> $a ap pr ri il l$
is --> $i is s$
the --> $t th he e$
cruelest --> $c cr ru ue el es st t$
```

وقی برای تمام سندهامون این بایگرم هارو استخراج کردیم میایم یک inverted-index روی بایگرم ها میسازیم . برای نمونه :

```
$i -> [1, 4, 34, 54, 55, 67]
```

و این چه معنی میده ؟ برای این نمونه معنیش میشه یک آرایه ایی از سند هایی که حرف i رو دارند . یعنی دو تا inverted-index خواهید داشت ، ی دونه مربوط به اون واژه نامه و سند ها هست و این یکی برای بایگرم ها هست .

## پردازش wildcard ها با شاخص bigram-index

برای نمونه متن `*mon` جست و جو میشه . ما چیکار میکنیم ؟ مانند قبل `$` رو میزاریم اول عبارت ، و چون انتهای عبارت جست و جوی ما چیزی قرار نگرفته دیگه نیاز نیست آخرش `$` بزاریم . بایگرم های این عبارت اینجوری حساب میشه :

```
mon* --> $m mo on
```

حال الگوریتم ما میره واژگانی رو پیدا میکنه که دارای این بایگرم ها باشند ، ولی همه باهم . اینجوری : 

```
$m AND mo AND on
```

یعنی الگوریتم دنبال واژگانی میگرده که همه ی بایگرم هارو داشته باشند و حتی اگه ی دونه از این بایگرم هارو نداشته باشند حساب نمیشند .
پس از اینکه تمامی اون واژگان پیدا شدند ، posting-list اونها باهم اشتراک گرفته میشه و ادغام میشه و نتیجه میاد بیرون که کدوم سند ها دارای عبارتی هستند که ما جست و جو کردیم .

> [!IMPORTANT] خوبی این روش
> از لحاظ حافظه بسیار کارا تر از permuterm-index هست .

> [!WARNING] نکته
> ما توی permuterm-index این FP رو نداشتیم . اما توی روش k-grams این FP رو خواهیم داشت .
> مانند واژه ی moon ، این واژه دقیقا طبق الگوریتم درست هست و دارای mon ، ولی یک پیش بینی نادرست یا FP هست و سند های دارای این بازیابی میشوند .

## شاخص های wildcard-query استفاده ی زیادی ندارند

امروزه موتور های جست و جو زیاد از wildcard-queries استفاده نمیکنند ، و دلیل آن هم هزینه ی سنگین پردازش آنهاست . در این الگوریتم ها باید از تعداد زیادی or و and استفاده شود و این برای پردازنده سنگین و زمان بر است .

و خیلی از موتور های جست و جو عمدا سراغ این روش نمیرن . چر ؟ چون کاربر ها توی نوشتن متن جست و جو تنبل هستند ، یک چیزی مینویسن و ی ستاره هم میزارن پشتش و تمام فشار رو میندازن رو شونه ی موتور جست و جو .
برای همین موضوع و جلوگیری از کند شدن موتور جست و جو ، کلا از این روش استفاده نمیشه .